{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['ITHEMAL_HOME'], 'learning', 'pytorch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common_libs.utilities as ut\n",
    "import data.data_cost as dt\n",
    "import functools\n",
    "from pprint import pprint\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOT_WIDTH = 16\n",
    "NUM_SLOTS = 8\n",
    "\n",
    "class Slot(object):\n",
    "    def __init__(self):\n",
    "        # type: () -> None\n",
    "        self.state = torch.randn(SLOT_WIDTH, requires_grad=True)\n",
    "        self.remaining_time = torch.zeros(1, requires_grad=True)\n",
    "        \n",
    "    def mutate(self, new_state, additional_time):\n",
    "        self.state = self.state * (self.remaining_time > 0).float() + new_state\n",
    "        old_time = self.remaining_time\n",
    "        self.remaining_time = self.remaining_time + additional_time\n",
    "        return old_time[0]\n",
    "    \n",
    "    def step(self, time):\n",
    "        self.remaining_time = torch.clamp(self.remaining_time - time, min=0)\n",
    "    \n",
    "    def read(self):\n",
    "        return torch.cat([self.remaining_time, self.state * (self.remaining_time > 0).float()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimulatorInput = NamedTuple('SimulatorInput', [\n",
    "    ('slot_vector', torch.tensor),\n",
    "    ('instruction_vector', torch.tensor),\n",
    "])\n",
    "\n",
    "SimulatorResult = NamedTuple('SimulatorResult', [\n",
    "    ('wait_time', torch.tensor),\n",
    "    ('write_head', torch.tensor),\n",
    "    ('write_state', torch.tensor),\n",
    "    ('write_time', torch.tensor),\n",
    "])\n",
    "ModelRunResult = NamedTuple('ModelRunResult', [\n",
    "    ('prediction', torch.tensor),\n",
    "    ('loss', torch.tensor),\n",
    "    ('slots', List[Slot]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_slots_from_result(slots, result):\n",
    "    loss = torch.tensor(0., requires_grad=True)\n",
    "    for i in range(NUM_SLOTS):\n",
    "        frac = result.write_head[i]\n",
    "        m_loss = slots[i].mutate(frac * result.write_state, frac * result.write_time)\n",
    "        loss = loss + frac * (1 + m_loss + result.write_state.norm()) # l1 loss of write head\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_embedder(emb_dim, max_n_srcs, max_n_dsts):\n",
    "    sym_dict, _ = ut.get_sym_dict()\n",
    "    embedder = torch.nn.Embedding(len(sym_dict), emb_dim)\n",
    "    clamp = lambda x: x if x < len(sym_dict) else len(sym_dict) - 1\n",
    "    \n",
    "    def get_emb_list(arr, length):\n",
    "        assert len(arr) <= length\n",
    "        real = [embedder(torch.tensor(clamp(val))) for val in arr]\n",
    "        zeros = [torch.zeros(emb_dim) for _ in range(length - len(arr))]\n",
    "        return real + zeros\n",
    "    \n",
    "    def embed(instr):\n",
    "        opc = embedder(torch.tensor(instr.opcode))\n",
    "        srcs = get_emb_list(instr.srcs, max_n_srcs)\n",
    "        dsts = get_emb_list(instr.dsts, max_n_dsts)\n",
    "        return torch.cat([opc] + srcs + dsts)\n",
    "        \n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralProcessorSimulator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralProcessorSimulator, self).__init__()\n",
    "        self.embedder = cat_embedder(128, 3, 3)\n",
    "        self.instr_vec_emb = nn.Linear(128*7, 128)\n",
    "        self.slot_vec_emb = nn.Linear((1+SLOT_WIDTH)*NUM_SLOTS, 128)\n",
    "        self.wait_time_out = nn.Linear(256, 1)\n",
    "        self.write_head_out = nn.Linear(256, NUM_SLOTS)\n",
    "        self.write_state_out = nn.Linear(256, SLOT_WIDTH)\n",
    "        self.write_time_out = nn.Linear(256, 1)\n",
    "        \n",
    "    def forward(self, instr_vec, slot_vec):\n",
    "        instr_vec = F.relu(self.instr_vec_emb(instr_vec))\n",
    "        slot_vec = F.relu(self.slot_vec_emb(slot_vec))\n",
    "        concat = torch.cat([instr_vec, slot_vec])\n",
    "        \n",
    "        wait_time = self.wait_time_out(concat).abs()\n",
    "        write_head = F.softmax(self.write_head_out(concat), dim=0)\n",
    "        write_state = self.write_state_out(concat)\n",
    "        write_time = self.write_time_out(concat).abs()\n",
    "        \n",
    "        return SimulatorResult(\n",
    "            wait_time=wait_time,\n",
    "            write_head=write_head,\n",
    "            write_state=write_state,\n",
    "            write_time=write_time,\n",
    "        )\n",
    "    \n",
    "def run_on_data(model, datum, debug=False):\n",
    "    block = datum.block\n",
    "    slots = [Slot() for _ in range(NUM_SLOTS)]\n",
    "    overfill_loss = torch.tensor(0., requires_grad=True)\n",
    "    wait_time = torch.tensor(0., requires_grad=True)\n",
    "\n",
    "    for i, instr in enumerate(block.instrs):\n",
    "        slot_vec = torch.cat([slot.read() for slot in slots])\n",
    "        instr_vec = model.embedder(instr)\n",
    "        result = model(instr_vec, slot_vec)\n",
    "        if debug:\n",
    "            print('Instr {}'.format(instr))\n",
    "            pprint(dict(vars(SimulatorResult(*[x.data for x in result]))))\n",
    "            print()\n",
    "        overfill_loss = overfill_loss + update_slots_from_result(slots, result)\n",
    "\n",
    "        if i == len(block.instrs) - 1:\n",
    "            break\n",
    "        wait_time = wait_time + result.wait_time[0]\n",
    "        for slot in slots:\n",
    "            slot.step(result.wait_time)\n",
    "\n",
    "    remaining_time = torch.max(torch.cat([slot.remaining_time for slot in slots]))\n",
    "    total_time = wait_time + remaining_time\n",
    "    wrongness_loss = F.mse_loss(total_time, torch.tensor(datum.y, requires_grad=True))\n",
    "    loss = overfill_loss + wrongness_loss\n",
    "    return ModelRunResult(total_time, loss, slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_processor_simulator = NeuralProcessorSimulator()\n",
    "optimizer = torch.optim.Adam(neural_processor_simulator.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_sgd(debug=False):\n",
    "    optimizer.zero_grad()\n",
    "    i = random.randrange(len(data.data))\n",
    "    datum = data.data[i]\n",
    "    result = run_on_data(neural_processor_simulator, datum, debug=debug)\n",
    "    result.loss.backward()\n",
    "    \n",
    "    sAPE = result.prediction / datum.y \n",
    "    print(' '*80, end='\\r')\n",
    "    print('sAPE: {:4.2f}, pred: {:6.2f}, actual: {:6.2f}, loss: {:8.2f}'.format(sAPE, result.prediction, datum.y, result.loss), end='\\r')\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_sgd(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    step_sgd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dt.load_dataset('../inputs/embeddings/code_delim.emb', '../inputs/data/time_skylake_test.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
