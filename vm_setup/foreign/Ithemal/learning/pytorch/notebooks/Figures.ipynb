{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import data.data_cost as dt\n",
    "import common_libs.utilities as ut\n",
    "import models.train as tr\n",
    "import models.graph_models as md\n",
    "import models.losses as ls\n",
    "from ithemal import ithemal_utils\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = dt.load_dataset('/home/ithemal/ithemal/learning/pytorch/inputs/embeddings/code_delim.emb', data_savefile='/home/ithemal/ithemal/learning/pytorch/saved/time_haswell_0131.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_of_block(self):\n",
    "    def paths_of_instr(i, parents):\n",
    "        new_parents = parents + [i]\n",
    "        if i.children:\n",
    "            return sum((paths_of_instr(c, new_parents) for c in i.children), [])\n",
    "        else:\n",
    "            return [new_parents]\n",
    "    return sum((paths_of_instr(i, []) for i in self.find_roots()), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([len(paths_of_block(d.block)) for d in full_data.data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.data[np.argmax(z)].block.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(z[z < 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_of_block(full_data.data[0].block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.data[0].block.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_ids = {d.code_id for d in full_data.test if mem_free(d)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_times = times[times['code_id'].isin(code_ids)]\n",
    "\n",
    "iaca_times = test_times[test_times['kind'] == 'iaca']\n",
    "iaca_preds = iaca_times.groupby('code_id').mean()\n",
    "\n",
    "llvm_times = test_times[test_times['kind'] == 'llvm']\n",
    "llvm_preds = llvm_times.groupby('code_id').mean()\n",
    "\n",
    "actual_times = test_times[test_times['kind'] == 'actual']\n",
    "actual_preds = actual_times.groupby('code_id').mean()\n",
    "# actual_preds = actual_preds.loc[iaca_preds.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((iaca_preds - actual_preds).abs() / actual_preds).mean()['time'])\n",
    "print(((llvm_preds - actual_preds).abs() / actual_preds).mean()['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(sum(1 + len(i.srcs) + len(i.dsts) for i in d.block.instrs) for d in data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haswell_data = full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sym_map(dataset):\n",
    "    m = collections.defaultdict(list)\n",
    "    for datum in dataset.raw_data:\n",
    "        (code_token, timing, code_intel, code_id) = datum\n",
    "        m[code_intel].append(datum)\n",
    "    return m\n",
    "haswell_sym_map = sym_map(haswell_data)\n",
    "skylake_sym_map = sym_map(skylake_data)\n",
    "nehalem_sym_map = sym_map(nehalem_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, dataset) in (\n",
    "    ('haswell', haswell_sym_map),\n",
    "    ('skylake', skylake_sym_map),\n",
    "    ('nehalem', nehalem_sym_map)\n",
    "):\n",
    "    torch.save([\n",
    "        random.choice(code) for code in dataset.values()\n",
    "    ], '../saved/time_{}_0131.data'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = dt.load_dataset('/home/ithemal/ithemal/learning/pytorch/inputs/embeddings/code_delim.emb', data_savefile='/home/ithemal/ithemal/learning/pytorch/saved/time_haswell_0113.data')\n",
    "orig_full_test = full_data.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_data.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablated_data = dt.load_dataset('/home/ithemal/ithemal/learning/pytorch/inputs/embeddings/code_delim.emb', data_savefile='/home/ithemal/ithemal/learning/pytorch/saved/time_haswell_0113.data')\n",
    "orig_ablated_test = ablated_data.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ithemal_utils.ablate_data(\n",
    "    ablated_data, \n",
    "    [\n",
    "        ithemal_utils.EdgeAblationType.NO_EDGES,\n",
    "        ithemal_utils.EdgeAblationType.ADD_LINEAR_EDGES,\n",
    "    ],\n",
    "    0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = ut.create_connection()\n",
    "times = pd.read_sql('SELECT time_id, code_id, time, kind FROM times WHERE arch=1', cnx).set_index('time_id')\n",
    "legal_code_ids = set(times[times['kind'] == 'iaca'].code_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_sql('SELECT code_id, code_token, code_intel, program, rel_addr, config_id FROM code', ut.create_connection()).set_index('code_id')\n",
    "codes['code_token'] = codes['code_token'].apply(lambda x: list(map(int, filter(bool, x.split(',')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = codes['code_token'].apply(lambda x: x.count(-1))\n",
    "codes['time'] = times[times['kind'] == 'actual'].groupby('code_id').mean()['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_code_ids = set(d.code_id for d in data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_instr_codes = codes[codes.index.isin(dataset_code_ids)]\n",
    "# single_instr_codes = single_instr_codes[n_splits == 3]\n",
    "# single_instr_codes['opcode'] = single_instr_codes['code_token'].apply(lambda x: x[0])\n",
    "# single_instr_nomem_codes = single_instr_codes[~single_instr_codes['code_token'].apply(lambda x: any(op >= data.mem_start for op in x))]\n",
    "\n",
    "nomem_codes = codes[codes.index.isin(dataset_code_ids)]\n",
    "nomem_codes = nomem_codes[~nomem_codes['code_token'].apply(lambda x: any(op >= data.mem_start for op in x))]\n",
    "\n",
    "# memfull_codes = codes[codes.index.isin(dataset_code_ids)]\n",
    "# memfull_codes = memfull_codes[memfull_codes['code_token'].apply(lambda x: any(op >= data.mem_start for op in x))]\n",
    "# # memfull_codes = memfull_codes[memfull_codes['code_token'].apply(lambda x: any(op == 5 for op in x))]\n",
    "# memfull_codes = memfull_codes[~memfull_codes['code_token'].apply(lambda x: any(op == 5 for op in x))]\n",
    "\n",
    "to_plot = nomem_codes\n",
    "\n",
    "variabilities = to_plot.groupby('code_intel').agg({'time': ['mean', 'std']})['time']\n",
    "variable_opcs = (variabilities['std'] / variabilities['mean']).dropna().sort_values()\n",
    "sns.distplot(variable_opcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = variabilities.sort_values('std').dropna()\n",
    "float(len(q[q['std'] < 1e-9])) / len(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes[codes['code_intel'] == 'vucomisd xmm14, xmm2\\nmov    edx, 0x00000001\\nsetp   al\\ncmovnz eax, edx\\ntest   al, al\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = codes[~codes.index.isin(set(times.code_id))]\n",
    "q = z[z['code_intel'] != '']\n",
    "lens = q['code_intel'].apply(lambda x: x.count('\\n') - 1)\n",
    "print(len(set(q['code_intel'])))\n",
    "sns.distplot(lens)\n",
    "# print(q.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_code_ids = {d.code_id for d in full_data.data}\n",
    "iaca_code_ids = set(times[times['kind'] == 'iaca'].code_id)\n",
    "mem_free_code_ids = {d.code_id for d in data.test if mem_free(d)}\n",
    "l = (new_code_ids & iaca_code_ids & mem_free_code_ids)\n",
    "idxs = [i for (i, d) in enumerate(data.test) if d.code_id in l]\n",
    "print(lstm_errs[idxs].mean())\n",
    "print(iaca_errs[idxs].mean())\n",
    "print(llvm_errs[idxs].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes['code_id'] = codes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {}\n",
    "for rec in codes.groupby('code_intel').agg({'time': 'mean', 'code_id': set}).to_records():\n",
    "    for cid in rec[1]:\n",
    "        pred[cid] = rec[2]\n",
    "pred = pd.DataFrame.from_dict(pred, orient='index', columns=['pred'])\n",
    "pred.index = pred.index.rename('code_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_times = times[times['kind'] == 'actual']\n",
    "actuals = ac_times[ac_times['code_id'].isin(l)].groupby('code_id').mean()\n",
    "actuals = actuals.loc[[d.code_id for d in data.test if d.code_id in l]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((actuals['time'] - pred['pred']).abs() / actuals['time']).dropna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes.loc[418511].time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(codes.loc[418511]['code_intel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = codes[codes.index.isin(set(times.code_id))]\n",
    "q = z[z['code_intel'] != '']\n",
    "lens = q['code_intel'].apply(lambda x: x.count('\\n') - 1)\n",
    "sns.distplot(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes['code_token_str'] = codes['code_token'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = codes[codes.index.isin({d.code_id for d in data.data})]\n",
    "print('num blocks: {}'.format(len(z)))\n",
    "groups = z.groupby(['code_intel']).agg(['size'])\n",
    "print('num unique blocks: {}'.format(len(groups)))\n",
    "groups_with_dup = groups[groups > 1]\n",
    "print('num groups w/ dup: {}'.format(len(groups_with_dup)))\n",
    "groups_with_dup.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(len(groups[groups<2])) / len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(groups_with_dup[groups_with_dup < 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_ids = [1, 2, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 100):\n",
    "    print()\n",
    "    print()\n",
    "    print(groups.sort_values().iloc[i])\n",
    "    print(groups.sort_values().index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(times[times['kind'] == 'actual'].code_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes[codes['code_intel'] == 'lea    rdx, [rdi+0x10]\\nmov    ecx, 0x00403850\\ntest   rcx, rcx\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opc = 846\n",
    "\n",
    "m_codes = single_instr_nomem_codes[single_instr_nomem_codes['opcode'] == opc].sort_values('time').dropna()\n",
    "sns.distplot(m_codes['time'])\n",
    "m_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_opcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = md.GraphNN(\n",
    "    256, 256, 1,\n",
    "    False, False, True\n",
    ")\n",
    "model.set_learnable_embedding(mode='none', dictsize=max(full_data.word2id) + 1)\n",
    "train = tr.Train(model, full_data, tr.PredictionType.REGRESSION, ls.mse_loss, 1)\n",
    "_ = train.load_checkpoint('../saved/paper_haswell_dag_sgd-6.mdl')\n",
    "actual, ithemal_dag_pred = train.validate('/tmp/res.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = md.GraphNN(\n",
    "    256, 256, 1,\n",
    "    False, False, True\n",
    ")\n",
    "model.set_learnable_embedding(mode='none', dictsize=max(ablated_data.word2id) + 1)\n",
    "train = tr.Train(model, ablated_data, tr.PredictionType.REGRESSION, ls.mse_loss, 1)\n",
    "_ = train.load_checkpoint('../saved/paper_haswell_lstm_sgd-6.mdl')\n",
    "_, ithemal_lstm_pred = train.validate('/tmp/res.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_code_ids = [d.code_id for d in data.test]\n",
    "def get_times_of_kind(kind):\n",
    "    filt = (times['kind'] == kind) & times['code_id'].isin(test_code_ids)\n",
    "    return (\n",
    "        times[filt]\n",
    "        .set_index('code_id')\n",
    "        .time\n",
    "        .loc[test_code_ids]\n",
    "        .values\n",
    "    )\n",
    "iaca_preds = get_times_of_kind('iaca')\n",
    "llvm_preds = get_times_of_kind('llvm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = np.array(actual)\n",
    "ithemal_dag_pred = np.array(ithemal_dag_pred)\n",
    "ithemal_lstm_pred = np.array(ithemal_lstm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "start = 0\n",
    "end = 1000\n",
    "bins = np.arange(start, end + 1, 20)\n",
    "\n",
    "ithemal_lstm_heatmap, _, _ = np.histogram2d(actual, ithemal_lstm_pred, bins=[bins, bins])\n",
    "ithemal_dag_heatmap, _, _ = np.histogram2d(actual, ithemal_dag_pred, bins=[bins, bins])\n",
    "# iaca_heatmap, _, _ = np.histogram2d(actual, iaca_preds, bins=[bins, bins])\n",
    "# llvm_heatmap, _, _ = np.histogram2d(actual, llvm_preds, bins=[bins, bins])\n",
    "\n",
    "for b in range(len(bins) - 1):\n",
    "    div = ithemal_lstm_heatmap[b, :].sum() or 1\n",
    "    ithemal_lstm_heatmap[b, :] /= div\n",
    "    ithemal_dag_heatmap[b, :] /= div\n",
    "\n",
    "heatmap = ithemal_lstm_heatmap - ithemal_dag_heatmap\n",
    "\n",
    "extreme = max(map(abs, (heatmap.T.max(), heatmap.T.min())))\n",
    "# extreme = 1\n",
    "extent = [start, end, start, end]\n",
    "# lognorm = matplotlib.colors.LogNorm(vmin = 20, vmax = heatmap.T.max(), clip = False)\n",
    "lognorm = None\n",
    "clim = (-extreme, extreme)\n",
    "# clim = None\n",
    "\n",
    "y_str = 'Predicted Throughput'\n",
    "x_str = 'Block Length'\n",
    "cmap = plt.get_cmap('bwr')\n",
    "# cmap.set_clim(-extreme, extreme)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.imshow(heatmap.T, cmap=cmap, norm=lognorm, extent=extent, origin='lower', clim=clim)\n",
    "plt.plot(np.linspace(start, end, 1000), np.linspace(start, end, 1000), 'k--', alpha=0.2)\n",
    "cbar = plt.colorbar()\n",
    "plt.tick_params(labelsize=10)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "ax.set_xlabel(x_str, fontsize=14)\n",
    "ax.set_ylabel(y_str, fontsize=14)\n",
    "ax.set_title('Haswell', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_free(datum):\n",
    "    for i in datum.block.instrs:\n",
    "        if any(s >= data.mem_start for s in i.srcs + i.dsts):\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ablated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mem_free = sum(1 for d in data.test if mem_free(d))\n",
    "n_mem_full = sum(1 for d in data.test if mem_free(d))\n",
    "print('mem free: {}, mem full: {}, total: {}, ratio: {}'.format(\n",
    "    n_mem_free,\n",
    "    n_mem_full,\n",
    "    len(data.test),\n",
    "    float(n_mem_free) / len(data.test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_blocks = [(i, d.block) for (i ,d) in enumerate(data.test) if 300 < d.y < 400 and mem_free(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bad_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 77/345 have 1 instr\n",
    "sum(1 for (_, d) in bad_blocks if len(d.instrs) == 1)\n",
    "# 76 are cmp (opc 172), 1 is test (opc 218)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(d for d in data.data for i in d.block.instrs if 'push' in str(i)).block.instrs[0].opcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "CMP = 172\n",
    "TEST = 218\n",
    "POP = 178\n",
    "PUSH = 176\n",
    "\n",
    "sns.distplot([d.y for d in data.data if len(d.block.instrs) == 1 and d.block.instrs[0].opcode in (POP,) and d.block.instrs[0].dsts[0] == 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = next(d for d in data.data if len(d.block.instrs) == 1 and d.block.instrs[0].opcode in (POP,) and d.y > 800 and d.block.instrs[0].dsts[0] == 6)\n",
    "# print(q.y)\n",
    "# print(q.code_id)\n",
    "# q.block.draw()\n",
    "\n",
    "q = next(d for d in data.data if len(d.block.instrs) == 1 and d.block.instrs[0].opcode in (POP,) and d.y < 200 \n",
    "         and d.block.instrs[0].dsts[0] == 4\n",
    "        )\n",
    "print(q.block.instrs[0].dsts[0])\n",
    "print(q.y)\n",
    "print(q.code_id)\n",
    "q.block.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.block.instrs[0].dsts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "z = collections.Counter()\n",
    "for (_, d) in bad_blocks:\n",
    "    if len(d.str) == \n",
    "    z[len(d.instrs)] += 1\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHARITH LOOK HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_blocks = [\n",
    "    (i, d.block) for (i, d) in enumerate(data.test) if \n",
    "    not mem_free(d) and \n",
    "    dag_errs[i] < 0.3 and \n",
    "    llvm_errs[i] > 0.6 and \n",
    "    600 < d.y < 1000\n",
    "]\n",
    "len(bad_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = [d.y for d in data.data if \n",
    "      len(d.block.instrs) == 1 \n",
    "      and not mem_free(d) and \n",
    "#      all(5 not in i.srcs for i in d.block.instrs) and\n",
    "#      all(5 not in i.dsts for i in d.block.instrs) and\n",
    "         d.block.instrs[0].opcode == 176\n",
    "#       and d.y > 100\n",
    "    ]\n",
    "sns.distplot(qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RE-RUN THIS CELL TO SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, block = random.choice(bad_blocks)\n",
    "print('Actual: {}, errs: DAG: {:.2f}, LSTM: {:.2f}, LLVM: {:.2f}, IACA: {:.2f}'.format(\n",
    "    actual[idx],\n",
    "    dag_errs[idx],\n",
    "    lstm_errs[idx],\n",
    "    llvm_errs[idx],\n",
    "    iaca_errs[idx],\n",
    "))\n",
    "block.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = next(b for b in data.data for i in b.block.instrs if ' ax' in str(i))\n",
    "q.block.instrs[-1].srcs\n",
    "q.block.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errof(preds):\n",
    "    return np.abs(actual - preds) / actual\n",
    "dag_errs = errof(ithemal_dag_pred)\n",
    "lstm_errs = errof(ithemal_lstm_pred)\n",
    "iaca_errs = errof(iaca_preds)\n",
    "llvm_errs = errof(llvm_preds)\n",
    "block_lens = np.array([len(d.block.instrs) for d in data.test])\n",
    "\n",
    "def plot_legal(legal, title):\n",
    "    max_txput = 1000\n",
    "    \n",
    "    legal_idxs = [i for i in range(len(data.test)) if legal(data.test[i])]\n",
    "    \n",
    "    errs = pd.DataFrame.from_items(\n",
    "        zip(actual, zip(dag_errs, lstm_errs, iaca_errs, llvm_errs)), \n",
    "        orient='index', \n",
    "        columns=['dag_errs', 'lstm_errs', 'iaca_errs', 'llvm_errs']\n",
    "    )\n",
    "    errs = errs.iloc[legal_idxs]\n",
    "    errs = errs[errs.index <= max_txput]\n",
    "\n",
    "    means = errs.groupby(pd.cut(errs.index, 50)).mean().dropna()\n",
    "    \n",
    "    mids = [i.mid for i in means.index]\n",
    "    err_ax = plt.gca()\n",
    "    err_ax.plot(mids, means.lstm_errs, label='LSTM errors')\n",
    "    err_ax.plot(mids, means.dag_errs, label='DAG errors')\n",
    "    err_ax.plot(mids, means.iaca_errs, label='IACA errors')\n",
    "    err_ax.plot(mids, means.llvm_errs, label='LLVM errors')\n",
    "    err_ax.set_ylabel('Average error')\n",
    "    err_ax.set_xlabel('Measured BB throughput')\n",
    "    err_ax.legend(loc=0)\n",
    "    \n",
    "    cdf_ax = err_ax.twinx()\n",
    "    legal_actual = actual[legal_idxs]\n",
    "    legal_block_lens = block_lens[legal_idxs]\n",
    "    actuals_to_hist = legal_actual[legal_actual <= max_txput]\n",
    "    vals, bins = np.histogram(actuals_to_hist, bins=1000)\n",
    "    vals = vals.astype(np.float64)\n",
    "    vals /= vals.sum()\n",
    "    vals = vals.cumsum()\n",
    "    mids = (bins[:-1] + bins[1:]) / 2\n",
    "    cdf_ax.plot(mids, vals, 'k--', label='CDF of block frequency')\n",
    "    cdf_ax.legend(loc=0)\n",
    "    \n",
    "    plt.title('{} ({:.2f}%, LSTM err: {:.3f}, DAG err: {:.3f})'.format(\n",
    "        title, \n",
    "        100.0 * len(legal_block_lens) / len(data.test),\n",
    "        lstm_errs.mean(),\n",
    "        dag_errs.mean(),\n",
    "    ))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_legal(mem_free, 'Memory-free blocks')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_legal(lambda x: not mem_free(x), 'Memory-containing blocks')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictable_idxs = [\n",
    "    i for (i, (_, r)) in enumerate(errs.iterrows()) if\n",
    "#     r['dag_errs'] < .5 * r['lstm_errs'] and\n",
    "#     r['dag_errs'] >= 0.05 and\n",
    "    mem_free(data.test[i]) and\n",
    "    actual[i] > 600 and actual[i] < 1000 and\n",
    "    len(data.test[i].block.instrs) > 1 and\n",
    "    True\n",
    "]\n",
    "len(predictable_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = random.choice(predictable_idxs)\n",
    "print('Test index {}\\n\\n{}\\n\\n'.format(\n",
    "    r,\n",
    "    '\\n'.join(map(str, data.test[r].block.instrs))\n",
    "))\n",
    "print('Actual: {}\\nDag pred: {:.0f} ({:.3f} err)\\nLSTM Pred: {:.0f} ({:.3f} err)'.format(\n",
    "    actual[r],\n",
    "    ithemal_dag_pred[r], errs.iloc[r]['dag_errs'],\n",
    "    ithemal_lstm_pred[r], errs.iloc[r]['lstm_errs'],\n",
    "))\n",
    "data.test[r].block.draw()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
